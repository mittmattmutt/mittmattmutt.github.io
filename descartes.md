# Contemporary philosophy introduced through Descartes

The aim of this post is to introduce some central arguments and themes in
contemporary analytic philosophy by connecting them to some arguments of
Descartes, who is typically recognised as the father of modern philosophy.

I want to do this for a couple of reasons. One us just that the arguments are
neat and interesting and deserving of widespread attention, and linking them to
Descartes, who many may have encountered in one way or another, is just a neat
pedagogical wrapping.

The second aim arises from this — if you’ve encountered Descartes, either
formally in class or via wiki or youtube or some other resource, you might be
left thinking that his project was both a failure and a misguided one at that.
My aim is to show this isn’t so: in an era of replicability crises and journal
hoaxes, Descartes’s aim to find a secure foundation for the sciences is
extremely relevant, and although we can’t follow in the particulars of his
footsteps, we should be attracted by its general motivations. Moreover,
reflecting on what a contemporary Cartesian project should look like can help us
to see how the concept and role of knowledge has changed in Western philosophy
and society more generally since the early modern period.

*****

A researcher in southern Germany, Erne Reaster, famous for doing work that
cleared up a few theoretical issues concerning the behaviour of supercool
liquids, recently published an article about how to solve the problems of
replicability, hoaxing, and other issues afflicting the production of science
today. Reaster, who has a PhD from MIT and was recently awarded a prestigious
research grant from the Dutch government, claimed that his system, which makes
us of certain recent work in game theory and Bayesian statistics, will finally
enable the doubts cast on modern science practice to be dispelled.

<span class="figcaption_hack">Descartes: Smart Dude.</span>

I made that up. Sorry. But I did so for a very good reason: it can be hard to
appreciate the greats of philosophy. It’s tempting to take an almost
condescending attitude towards them, because more or less as soon as we’re
introduced to them we’re introduced to certain insuperable problems they face.
Aristotle is introduced in one breath and said to be superseded by advances in
science and logic in the next; we’re told of Kant’s critical project with the
parenthesis that, of course, given developments in non-Euclidean geometry, it’s
a non-starter. And soon after we learn about Descartes, we’re told about the
infamous Cartesian circle which scuppers his project.

But Descartes was a smart cookie. And although it’s impossible to say, or even
really make sense of, I think that were he around today he would be like our
fictitious Reaster: a respected scientist whose goal was to reform the practice
of a discipline in crisis. And, I hope you agree, condescension would not be the
appropriate attitude to take to such a thinker.

Descartes, like Reaster, was a scientific prodigy, at the vanguard of discipline
after discipline. Like Reaster, he lived in an era when scientific method was
being impugned (albeit it instead of hoaxing and replication, he was worried
that merely suggesting observation, as opposed to Aristotelian first principles,
could lead to knowledge might have the Catholic church and their pitchforks
knocking at your door). And like Reaster, he wanted to set scientific method on
the right footing, using the best methods at his disposal.

*****

But that was about 400 years ago. It was before calculus (indeed, Descartes’s
work in pure maths was a precursor thereto), long before statistics, a time when
Bayesian epistemology wasn’t a thing, indeed epistemology in general was barely
a thing. And so Descartes started from a notably different position than our
imagined Reaster.

In particular, he started, not with game theory and with statistics, but with
himself and what he could and could not doubt. His aim was to find things of
which he could be *certain*.

That’s reasonable enough, especially for someone with the mathematical
background Descartes had, because mathematics deals in certainty. He thought if
he could just establish a sound foundation of knowledge, then everything built
upon it would be trustworthy. But what could such a foundation be? What could be
known with certainty?

That’s not so easy to answer. Sitting in his room, he realized … well, he
realized he *thought* he was sitting in his room, but sometimes people think
things — because they’re deluded, or mentally ill, or perhaps dreaming — that
are completely false. If he was dreaming, then he wasn’t sitting in his room.
Since he couldn’t be certain he wasn’t dreaming (or hallucinating, etc.), he
could doubt that he was sitting in his room, and since he was looking for
something certain, he had to give up the thought that perception furnishes the
foundations he was looking for. Fair enough. Maybe empirical knowledge is no
good. But there are other sorts of knowledge: what about his mathematics, which
doesn’t depend on experience in this way?

But, he says, it could be that an evil demon has tricked him, so that although
it seems to him he’s certain that two and two is four, he’s actually deceived.
So we can’t even believe in such necessary truths: again, even a smidgen of
doubt, even owing to the outlandish possibility of an evil demon, is sufficient
to impugn mathematical knowledge.

Despairing, he thinks to himself: I doubt everything! I know nothing. But wait a
second. If it’s true that he doubts everything, then it’s true that he’s
thinking, because doubting is a type of thinking. So if it’s true that he doubts
everything, then at the time he’s doubting, it’s true that he’s thinking (even
if he can doubt that he’s doubting, he’s still doubting, and so still thinking).
And so there seems to be some thing that by its very nature he cannot doubt,
namely that he is thinking. And this is the famous cogito argument: *cogito*, he
says to himself, which is Latin for ‘I think’, and so *sum* — ‘I am’. He can’t
conclude that his body exists: only that as a thinking thing he exists, and so
he is drawn to conclude that his mind and his body are two different things,
because they differ in their dubitability.

From that foundation, he attempts to rebuild the knowledge he’s cast in doubt.
It’s generally agreed that he fails mightily in this (partly because of the
Cartesian circle, mentioned above, but which I won’t get into), but we should
agree at least that his project was and is a worthwhile one.

*****

There are a couple of things I want to note: there’s doubt, the fear that you’re
misled in a massive way — the worry of *skepticism* brought up by the
possibility that you’re dreaming, or the plaything of an evil supernatural
creature. There’s the importance of certainty — of knowledge, we might say. And
there’s the difference between *mind and body* — and in particular in the
thought that we have some *super special guaranteed access to the mind* that
differentiates it from the body.

Skepticism — difference between mind and body — special access to the mind.
Before going on, think to yourself: which of these views are most likely to have
been discarded and which retained by contemporary thinkers? Do you think
philosophers still take seriously the possibility of evil demons misleading us,
or there being an important distinction between mind and body, or that the
contents of the mind are in some sense easier to know than the nature of the
body?

I hope your answers are: no, no, yes. Because those are exactly the wrong
answers, as I will now show by running through three interesting and influential
arguments from contemporary philosophy. I begin with the third question.

#### How much do we know our own minds?

Timothy Williamson’s 2001 book *Knowledge and Its Limits* is arguably the most
influential work yet published in the 21st century (if you’re extremely
ambitious and want to dive in to contemporary philosophy, I might recommend
getting it and slogging through.) And one of its central claims is that we
don’t, contrary to what we might think, have a very special epistemic grasp on
the contents of our minds.

The argument’s target is the following (I here and throughout dejargonify and
simplify, sometimes omitting important details for the sake of expository ease
while still retaining enough detail to let you see both form and content of the
arguments.)

**(Luminosity)** Many mental states are such that, whenever we’re in them, we
can know we’re in them.

Let’s think about this for a while. We have mental states: fear, belief, desire,
pain, and so on. And there’s something special about our own mental states as
against the mental states of others or states of the external world. They’re
closer to us: we can know them *more easily*, just by introspecting. It’s easier
for me to know I’m in pain than for me to know you are. This ease of knowledge
might led one to think that if you’re in pain, you ipso facto* know* you’re in
pain.

Williamson’s argument challenges this. It’s not always true that when you’re in
pain, you can know you’re in pain — even if you’re paying close attention to
yourself, you’re not on opiates, you don’t have pain asymbolia or other such
things. You yourself right now could be in pain and not know it.

How? The crucial assumption underlying the argument is this:

**(Reliability)** Your belief in something only counts as knowledge if, in
similar situations in which the thing was false, you wouldn’t also still believe
that thing.

To see this, compare these two people: one of them thinks it’s always 9:20am,
and says so every minute on the minute. Another person looks at the clock every
minute and says what time the clock reads, and believes it’s that time. It’s
9:20am. Both say that it’s 9:20am, but the first doesn’t know because, if it
were 9:21am, they would still say it’s 9:20am. The second does know because, if
it were 9:21am, he wouldn’t still believe that it was 9:20am. The second is a
*reliable* time teller; the first is not.

Now, imagine this scenario: you wake up one morning at 9am, and you’re cold, but
you gradually warm up so that by noon you’re warm. In particular, imagine that
for all minutes *m*, you’re less cold at *m*+1 than you were at *m*. But also,
as is plausible, assume that for all minutes, you can’t tell the difference
between *m* and *m*+1: they feel exactly the same to you, temperature-wise. On
this basis, assume the following:

(**Premise**) If, at *m*, you know you feel cold, then at *m*+1 you feel cold.

This is the big and crucial premise. Williamson’s justification for it
introduces details I’ve suppressed, so hopefully this is a way of putting it:
*m*+1 feels exactly the same to you as *m*, by the gradualness hypothesis. In
any two situations which feel exactly the same to you, you believe the same
things, otherwise you’re not epistemically reliable. So, in *m*+1, you believe
that you feel cold. But if in *m*+1 you *don’t* feel cold, then you believe
falsely, and if you believe falsely in a similar case, then you don’t reliably
know. So this premise follows from the reliability assumption.

(Think about a variation of the clocks case to see this: Imagine entering a room
that just tells you the hour on some device. It reads 9am; you say and believe
it’s 9am. It seems reasonable to say that you know it; but if after a few
minutes, without the clock changing, you suddenly say and start to believe it’s
10am, it seems like there’s something dodgy going on, and you’re not reliable
anymore.)

With that premise, we can make trouble. We can assume that at 9am you feel cold.
Assuming Luminosity, we conclude that at 9am, you know you feel cold. From the
Premise, we conclude that at 9:01am, you feel cold. From the Luminosity
assumption, we again conclude that you know you feel cold, and from the Premise,
we again conclude that at 9:02am you feel cold.

It’s clear we can keep going all the way to noon, and we’ll then have the result
that at noon you are, and know yourself to be, cold. But that contradicts the
description of the case: at noon, you are warm. So the reliability assumption,
as manifested in the premise, and the luminosity assumption, jointly lead to a
contradiction.

So if we like reliability, we must ditch luminosity. And that means that
sometimes we can be in a mental state, but unable to know that we’re in that
mental state. We do not have special epistemic access to our own mental states,
something that would have surprised both Descartes and, I think, most of us
still today.

*****

Descartes appealed to an evil genius who could make it the case that everything
he thought he experienced was in fact illusory. You might think that this
somewhat out there possibility is a bit unserious. But if you do take it
seriously — perhaps because you watched films like The Matrix, which are guided
by a roughly similar premise — you might think, well, we’re screwed. If we’re so
deeply illuded, there’s no hope for us, epistemically speaking.

An ingenious argument by Hilary Putnam, however, challenged this (it is found in
the first chapter of his 1982 book *Reason, Truth, and History*). I should say
before going on that while both the luminosity argument above and the dualism
argument we’ll consider below are live concerns, the sorts of issues raised here
are less pressing in contemporary philosophy. But they were so roughly a
generation ago, and it’s worth knowing them, even if not for their intrinsic
interest (which is great, I think), but for their historical importance.

Putnam introduces the science-fictional hypothesis that we are brains in vats.
Some dastardly scientist, somehow, caused a bunch of brains to be generated just
like ours from some special material that he kept in a vat. When the brain was
fully formed, he put some preservative liquid in the vat and connected the brain
up to wires. These wires lead to a computer, and that computer simulates
experiences just like ours. You are to consider that you are such a
brain-in-a-vat: that the computer or phone in front of you is illusory, as are
the trees outside your window, your body, and everything else.

Now, should we be worried about that? Set aside what we may call existential
worries — like whether being envatted precludes one from having an enjoyable and
worthwhile (albeit simulated) life. We’re talking about truth and knowledge —
should we be concerned that it might be true that we’re brains in vats, and thus
that everything we know about the world is false?

Putnam thinks no. Roughly speaking, it can’t be that everything that we know
about the world is false because the product of the vat’s computer program
because, if we are indeed brains in vats, the world is just *is* the computer
program. To explain this a bit more clearly, it’s necessary to take brief detour
through some philosophy of language.

In the 20th and on into the 21st century there have been two main theories about
how language connects to the world. On one, a word, say ‘gold’, stands for a
particular bit of reality (the sum total of the world’s gold), because there is
associated with the word a description that describes that sum total, like *the
bright metal more malleable than any other*. Call this the descriptivist theory.
On the other theory, ‘gold’ stands for the gold because there is some causal
connection between people’s use of the word ‘gold’ and the stuff in the world.
Roughly, when someone first encountered gold they said ‘let’s call that ‘gold’’
pointing to an example of gold. They talked about gold to their friends, whose
use of ‘gold’ became casually connected, at one remove, to gold. *They* then in
turn talked to *their* friends, and so on, such that my use of gold, via a bunch
of intermediary people, can be traced back to the original baptising of gold,
and that link makes it that ‘gold’ means the stuff that was baptised. The key
point is the causal point: words stand for the things to which they are causally
connected.

A consequence of this is that you can only speak and think about something if
you’ve had some causal contact with it, either directly (if you’re the one who
stood in front of gold and gave it its name) or indirectly (if you belong to a
linguistic community that bears some connection to the person who originally
gave it its name.)

But now think about our brains in vats. What have they had causal connection
with? Well, it’s unclear. We might want to say that what they’re causally
connected to is certain images the computer program produces, or maybe the
underlying code responsible, or maybe nothing at all. One thing is clear: brains
in vats have never been in causal contact with the vats in which their brains
are envatted. They have never escaped from their vats to realize their
situation. That means that they can’t think or talk about vats. Just as there
are out in deep space craters shaped like my face (probably — space is big) that
I can’t refer to because I’ve never been in causal contact with them, so brains
in vats, having never been in contact with vats, can’t refer to them. That means
that when a brain in a vat says ‘I’m a brain in a vat’, they don’t say something
true. At best, they say that they are a brain in a vat *in the computer
simulation *(just as, at best, when they say ‘I’m reading something’, they say
that they are reading something *in the computer simulation*). But this means,
if you’re a brain in a vat, you shouldn’t worry about being a brain in a vat —
you can know, just because of how language works, that it’s false.

You may not like this argument: many people think it’s a big trick, and that it
doesn’t really do much to assuage the fear that one is in a skeptical scenario.
But I hope you agree it’s interesting and it does show how considerations from
developments in philosophy — in particular about how language works — have shed
new light on age old problems, and how such problems have developed.

*****

Descartes thought that because he couldn’t doubt that he was thinking, when he
was thinking, that enabled him also not to doubt that he was a thinking thing.
On the other hand, because he could doubt that he had a body, he was able to
doubt that he was a physical thing, and was thus led to posit dualism: that he
was both mind and body, which are two different things.

You might think that today, because we know so much more about the brain and
about biology in general, and because we tend to give less credence to
religious-sounding concepts like souls or spirits, that such a view would find
little favour. The mind, you might think, is just somehow the body, that it
arises from it and its operations can be explained entirely in terms of how the
brain works, which can in turn be explained entirely in terms of physics,
eventually. We don’t need to posit minds in addition to bodies, which would be
weird entities hard to square with scientific progress.

But contemporary philosophy of mind takes quite seriously the thought that the
mind might be special and might require, for its explanation, going beyond the
properties the physical sciences countenance. And one of the central arguments
for doing so is somewhat — only somewhat — similar to Descartes’s. This is David
Chalmer’s famous zombie argument, presented in his 1996 *The Conscious Mind* and
in several works subsequently.

The argument tends to be formulated using a somewhat technical apparatus of
what’s called two-dimensional semantics. I’m not sure I’m entirely on board with
the necessity of using such apparatus for this purpose, and because it would
take a long time to explain, I won’t bother.

Which is okay, because the argument can be presented quickly and clearly enough
without it. A zombie is a creature that is an exact duplicate of a human being,
but that lacks consciousness. Zombies — as far as we know — don’t exist in the
real world, but they could exist. How do we know they could exist? Well, we can
imagine they exist. We can picture a world in which there are creatures just
like us — creatures going about their Sunday, eating their dinner, talking to
their friends, going for walks by the sea, and so on, but for whom, unlike us,
those experiences aren’t accompanied by conscious experience. They don’t taste
the sharpness of the tomatoes, the cold of the sea air, the emotional warmth of
talking to someone you like. But if we can imagine that so readily, then we
should think it’s possible.

But that causes problems. To see this, let’s say a bit more about materialism.
Materialism is the idea that, once we’ve got the physical properties, we get the
other ones for free. Biological, chemical, economic, and so on properties all
depend on the physical properties; they are nothing over and above those
properties.

This talk of nothing over and aboveness might strike you as vague. It is, but
that’s on me. There is a lot (like, *a lot a lot*) of philosophical work on this
topic, but I can’t get into it here. But here is one thing we can say: if you
like materialism, then you should like the following principle. We can imagine
possible worlds other than ours: worlds in which kangaroos fly, for example, or
there is a one hundred mile tall building.

Now imagine two possible worlds in which the same physical properties are
distributed the same way: if in world one there’s a particle with a given mass
at point *p*, so there is in world two. If there’s a field with a certain force
at a location *l* in world one, a field with the same properties is in the same
place in two, and so on for every fundamental physical entity and property.

If you like materialism, you should say that both these worlds instantiate all
and only the same properties of any type: they instantiate the same biological
properties, the same chemical properties, the same economic properties, and so
on, and they do so precisely because they instantiate the physical properties.
That’s just a fancy way of saying, really, that these other properties are
nothing over and above the physical ones.

Now to the problem: we’ve assumed that it’s possible for zombies to exist.
Translated into possible worlds talk, we’re saying that two worlds share all
their physical (and thus biological, chemical, etc.) properties, but in one
there is, and in the other there is not, conscious experiences. That is to say,
in one there is, and in the other there is not, consciousness properties. But
then that means that some properties *are* over and above physical ones, namely
conscious ones, and so that gives us a picture of a world with two types of
properties, physical and consciousness one, and that seems kind of like the
Cartesian picture.

*****

So those are our three arguments. To repeat, these have each been very
influential, and have been or are taken very seriously. They give a good outline
of part of the landscape of contemporary analytic philosophy.

You might not like them. If you don’t, I encourage you to think about why you
don’t like them, think how you would clearly object to them, and so on. If
nothing else, doing philosophy like that is a fun mental exercise.

I want to end with — I think — a slightly original point. Descartes sought
scientific knowledge, and thus led him to seek for certainty in himself, for
sure foundations. This has been enormously influential, and arguably our very
concept of knowledge owes much to him, even if we don’t realize it.

Maybe we need to change our concept of knowledge today. It certainly seems like
our culture is one in which the status of knowledge is uncertain. We have
replicability crises, and hoaxes and other fears about peer review, not to
mention fake news and culture wars outside of academia. But maybe Descartes
offers us a hint as to how to proceed: knowledge is scientific knowledge, and
that, today, is the knowledge produced by the institutions of scientific
learning. That is, it’s something crucially involved with institutions, rather
than something that a guy in a room by himself can figure out.

If that is so, then we need to ask hard questions about the roles that
institutions play in generating or suppressing knowledge. We need to ask about
how the publish-or-perish culture encourages sloppy or downright fradulent
research, how the mechanisms for preventing it are imperfect, how certain voices
are excluded while others are magnified (say, by institutional privilege, or
citation networks), and other such questions. That is to say, a Cartesian
project for the 21st century would have to realize the social element of how
knowledge is created and disseminated. Our modern day Descartes, Erne Reacher,
would, in the service of setting science on secure foundations, be studying bias
and privilege and power, and those who think that studying such things is a
waste of time — is a pointless exercise in grievance studies — are not, as they
might like to think, the rightful heirs to the Cartesian project of furthering
scientific knowledge but are in fact hindering it.

